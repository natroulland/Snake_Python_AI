<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns:z="http://www.zotero.org/namespaces/export#"
 xmlns:bib="http://purl.org/net/biblio#"
 xmlns:foaf="http://xmlns.com/foaf/0.1/"
 xmlns:dcterms="http://purl.org/dc/terms/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:link="http://purl.org/rss/1.0/modules/link/"
 xmlns:prism="http://prismstandard.org/namespaces/1.2/basic/"
 xmlns:vcard="http://nwalsh.com/rdf/vCard#">
    <bib:Report rdf:about="#item_1">
        <z:itemType>report</z:itemType>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>ROULLAND</foaf:surname>
                        <foaf:givenName>Nathan</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_2"/>
        <dc:title>Veille</dc:title>
    </bib:Report>
   <bib:Memo rdf:about="#item_2"><rdf:value></rdf:value></bib:Memo>
    <bib:Document rdf:about="https://www.zotero.org/user/validate/42e46addd6299e3127cf">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <link:link rdf:resource="#item_6"/>
        <dc:title>Zotero | Email validation</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.zotero.org/user/validate/42e46addd6299e3127cf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:29:59</dcterms:dateSubmitted>
    </bib:Document>
    <z:Attachment rdf:about="#item_6">
        <z:itemType>attachment</z:itemType>
        <dc:title>Zotero | Email validation</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.zotero.org/user/validate/42e46addd6299e3127cf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:30:05</dcterms:dateSubmitted>
        <z:linkMode>1</z:linkMode>
        <link:type>text/html</link:type>
    </z:Attachment>
    <bib:Recording rdf:about="https://www.youtube.com/watch?v=Wo5dMEP_BbI">
        <z:itemType>videoRecording</z:itemType>
        <z:directors>
            <rdf:Seq>
                <rdf:li>
                   <foaf:Person><foaf:surname>sentdex</foaf:surname></foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </z:directors>
        <dc:title>Neural Networks from Scratch - P.1 Intro and Neuron Code</dc:title>
        <dcterms:abstract>Building neural networks from scratch in Python introduction.

Neural Networks from Scratch book: https://nnfs.io

Playlist for this series:    • Neural Networks from Scratch in Python  

Python 3 basics: https://pythonprogramming.net/introdu...
Intermediate Python (w/ OOP): https://pythonprogramming.net/introdu...

Mug link for fellow mug aficionados: https://amzn.to/2xcyfPC 

Channel membership:    / @sentdex  
Discord:   / discord  
Support the content: https://pythonprogramming.net/support...
Twitter:   / sentdex  
Instagram:   / sentdex  
Facebook:   / pythonprogramming.net  
Twitch:   / sentdex  

#nnfs #python #neuralnetworks</dcterms:abstract>
        <dc:date>2020-04-11</dc:date>
        <z:libraryCatalog>YouTube</z:libraryCatalog>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://www.youtube.com/watch?v=Wo5dMEP_BbI</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:34:51</dcterms:dateSubmitted>
        <z:runningTime>16:58</z:runningTime>
    </bib:Recording>
    <bib:Document rdf:about="https://www.youtube.com/playlist?list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <link:link rdf:resource="#item_9"/>
        <dc:title>Neural Networks from Scratch in Python - YouTube</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.youtube.com/playlist?list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:35:51</dcterms:dateSubmitted>
    </bib:Document>
    <z:Attachment rdf:about="#item_9">
        <z:itemType>attachment</z:itemType>
        <dc:title>(2) Neural Networks from Scratch in Python - YouTube</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.youtube.com/playlist?list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:36:12</dcterms:dateSubmitted>
        <z:linkMode>1</z:linkMode>
        <link:type>text/html</link:type>
    </z:Attachment>
    <bib:Document rdf:about="https://www.youtube.com/watch?v=ncj_hBfRt-Y&amp;ab_channel=ThibaultNeveu">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <dc:title>Comprendre les algorithmes génétiques #1 - YouTube</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.youtube.com/watch?v=ncj_hBfRt-Y&amp;ab_channel=ThibaultNeveu</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:36:47</dcterms:dateSubmitted>
    </bib:Document>
    <bib:Document rdf:about="https://dev.to/n8python/attempting-and-sort-of-succeeding-to-implement-neat-in-javascript-2ea6">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website><dc:title>DEV Community</dc:title></z:Website>
        </dcterms:isPartOf>
        <link:link rdf:resource="#item_12"/>
        <dc:title>Attempting (And Sort of Succeeding) to Implement NEAT in JavaScript</dc:title>
        <dcterms:abstract>Backstory   Recently, I was competing with my friend to see who create the AI that could wal...</dcterms:abstract>
        <dc:date>2020-09-05</dc:date>
        <z:language>en</z:language>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://dev.to/n8python/attempting-and-sort-of-succeeding-to-implement-neat-in-javascript-2ea6</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:37:13</dcterms:dateSubmitted>
    </bib:Document>
    <z:Attachment rdf:about="#item_12">
        <z:itemType>attachment</z:itemType>
        <dc:title>Snapshot</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://dev.to/n8python/attempting-and-sort-of-succeeding-to-implement-neat-in-javascript-2ea6</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:37:22</dcterms:dateSubmitted>
        <z:linkMode>1</z:linkMode>
        <link:type>text/html</link:type>
    </z:Attachment>
    <bib:Article rdf:about="https://direct.mit.edu/evco/article/10/2/99-127/1123">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:1063-6560,%201530-9304"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Stanley</foaf:surname>
                        <foaf:givenName>Kenneth O.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Miikkulainen</foaf:surname>
                        <foaf:givenName>Risto</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_13"/>
        <dc:title>Evolving Neural Networks through Augmenting Topologies</dc:title>
        <dcterms:abstract>An important question in neuroevolution is how to gain an advantage from evolving neural network topologies along with weights. We present a method, NeuroEvolution of Augmenting Topologies (NEAT), which outperforms the best ﬁxed-topology method on a challenging benchmark reinforcement learning task. We claim that the increased efﬁciency is due to (1) employing a principled method of crossover of different topologies, (2) protecting structural innovation using speciation, and (3) incrementally growing from minimal structure. We test this claim through a series of ablation studies that demonstrate that each component is necessary to the system as a whole and to each other. What results is signiﬁcantly faster learning. NEAT is also an important contribution to GAs because it shows how it is possible for evolution to both optimize and complexify solutions simultaneously, offering the possibility of evolving increasingly complex solutions over generations, and strengthening the analogy with biological evolution.</dcterms:abstract>
        <dc:date>06/2002</dc:date>
        <z:language>en</z:language>
        <z:libraryCatalog>DOI.org (Crossref)</z:libraryCatalog>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://direct.mit.edu/evco/article/10/2/99-127/1123</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:37:27</dcterms:dateSubmitted>
        <bib:pages>99-127</bib:pages>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:1063-6560,%201530-9304">
        <prism:volume>10</prism:volume>
        <dc:title>Evolutionary Computation</dc:title>
        <dc:identifier>DOI 10.1162/106365602320169811</dc:identifier>
        <prism:number>2</prism:number>
        <dcterms:alternative>Evolutionary Computation</dcterms:alternative>
        <dc:identifier>ISSN 1063-6560, 1530-9304</dc:identifier>
    </bib:Journal>
    <z:Attachment rdf:about="#item_13">
        <z:itemType>attachment</z:itemType>
        <dc:title>Stanley et Miikkulainen - 2002 - Evolving Neural Networks through Augmenting Topolo.pdf</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:37:23</dcterms:dateSubmitted>
        <z:linkMode>1</z:linkMode>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Document rdf:about="https://realpython.com/python-ai-neural-network/">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Python</foaf:surname>
                        <foaf:givenName>Real</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_16"/>
        <dc:title>Python AI: How to Build a Neural Network &amp; Make Predictions – Real Python</dc:title>
        <dcterms:abstract>In this step-by-step tutorial, you'll build a neural network from scratch as an introduction to the world of artificial intelligence (AI) in Python. You'll learn how to train your neural network and make accurate predictions based on a given dataset.</dcterms:abstract>
        <z:language>en</z:language>
        <z:shortTitle>Python AI</z:shortTitle>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://realpython.com/python-ai-neural-network/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:38:53</dcterms:dateSubmitted>
    </bib:Document>
    <z:Attachment rdf:about="#item_16">
        <z:itemType>attachment</z:itemType>
        <dc:title>Snapshot</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://realpython.com/python-ai-neural-network/</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:39:00</dcterms:dateSubmitted>
        <z:linkMode>1</z:linkMode>
        <link:type>text/html</link:type>
    </z:Attachment>
    <bib:Document rdf:about="https://www.google.com/search?q=how+to+create+a+neural+network+in+python&amp;rlz=1C1VDKB_frFR1037FR1037&amp;oq=how+to+create+a+neura&amp;gs_lcrp=EgZjaHJvbWUqBwgAEAAYgAQyBwgAEAAYgAQyBggBEEUYOTIHCAIQABiABDIICAMQABgWGB4yCAgEEAAYFhgeMggIBRAAGBYYHjIICAYQABgWGB4yCAgHEAAYFhgeMggICBAAGBYYHjIICAkQABgWGB7SAQkxMjU4N2owajSoAgCwAgA&amp;sourceid=chrome&amp;ie=UTF-8#fpstate=ive&amp;vld=cid:51146c08,vid:MQzG1hfhow4,st:0">
        <z:itemType>webpage</z:itemType>
        <dcterms:isPartOf>
           <z:Website></z:Website>
        </dcterms:isPartOf>
        <link:link rdf:resource="#item_18"/>
        <dc:title>how to create a neural network in python - Recherche Google</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.google.com/search?q=how+to+create+a+neural+network+in+python&amp;rlz=1C1VDKB_frFR1037FR1037&amp;oq=how+to+create+a+neura&amp;gs_lcrp=EgZjaHJvbWUqBwgAEAAYgAQyBwgAEAAYgAQyBggBEEUYOTIHCAIQABiABDIICAMQABgWGB4yCAgEEAAYFhgeMggIBRAAGBYYHjIICAYQABgWGB4yCAgHEAAYFhgeMggICBAAGBYYHjIICAkQABgWGB7SAQkxMjU4N2owajSoAgCwAgA&amp;sourceid=chrome&amp;ie=UTF-8#fpstate=ive&amp;vld=cid:51146c08,vid:MQzG1hfhow4,st:0</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:39:17</dcterms:dateSubmitted>
    </bib:Document>
    <z:Attachment rdf:about="#item_18">
        <z:itemType>attachment</z:itemType>
        <dc:title>how to create a neural network in python - Recherche Google</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.google.com/search?q=how+to+create+a+neural+network+in+python&amp;rlz=1C1VDKB_frFR1037FR1037&amp;oq=how+to+create+a+neura&amp;gs_lcrp=EgZjaHJvbWUqBwgAEAAYgAQyBwgAEAAYgAQyBggBEEUYOTIHCAIQABiABDIICAMQABgWGB4yCAgEEAAYFhgeMggIBRAAGBYYHjIICAYQABgWGB4yCAgHEAAYFhgeMggICBAAGBYYHjIICAkQABgWGB7SAQkxMjU4N2owajSoAgCwAgA&amp;sourceid=chrome&amp;ie=UTF-8#fpstate=ive&amp;vld=cid:51146c08,vid:MQzG1hfhow4,st:0</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:39:20</dcterms:dateSubmitted>
        <z:linkMode>1</z:linkMode>
        <link:type>text/html</link:type>
    </z:Attachment>
    <bib:Recording rdf:about="https://www.youtube.com/watch?v=L8ypSXwyBds">
        <z:itemType>videoRecording</z:itemType>
        <dc:title>Python + PyTorch + Pygame Reinforcement Learning – Train an AI to Play Snake</dc:title>
        <dcterms:abstract>In this Python Reinforcement Learning course you will learn how to teach an AI to play Snake! We build everything from scratch using Pygame and PyTorch.

💻 Code: https://github.com/python-engineer/sn...

✏️ Course developed by Python Engineer. Check out his YouTube channel:    / @patloeber  

🎨 Art by Rachel: http://rachel.likespizza.com/

⭐️ Course Contents ⭐️
⌨️ (0:00:00) Part 1: Basics of Reinforcement Learning and Deep Q Learning
⌨️ (0:17:22) Part 2: Setup environment and implement snake game
⌨️ (0:40:07) Part 3: Implement agent to control game
⌨️ (1:10:59) Part 4: Create and train neural network

🎉 Thanks to our Champion and Sponsor supporters:
👾 Raymond Odero
👾 Agustín Kussrow
👾 aldo ferretti
👾 Otis Morgan
👾 DeezMaster

--

Learn to code for free and get a developer job: https://www.freecodecamp.org

Read hundreds of articles on programming: https://freecodecamp.org/news</dcterms:abstract>
        <dc:date>2022-04-25</dc:date>
        <z:libraryCatalog>YouTube</z:libraryCatalog>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://www.youtube.com/watch?v=L8ypSXwyBds</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:39:46</dcterms:dateSubmitted>
        <z:runningTime>1:38:33</z:runningTime>
    </bib:Recording>
    <bib:Recording rdf:about="https://www.youtube.com/watch?v=gPVVsw2OWdM">
        <z:itemType>videoRecording</z:itemType>
        <dc:title>Comprendre le DeepLearning et les Réseaux de neurones en 10 mins !</dc:title>
        <dcterms:abstract>Dans cette vidéo de vulgarisation je vais tenter de vous expliquer ce qu'est le deeplearning sans rentrer dans des détails de maths compliquées.
A la fin de la vidéo vous aurez une bonne intuition de comment un réseau de neurons est construit et comment il apprend. Le deeplearning est une branche de l'intelligence artificielle
qui est très à la mode en ce moment avec le big data. C'est une methode qui permet de faire des prédictions sur des données. Nous allons découvrir les 2 étapes clés que sont le 
FeedForward et la Backpropagation
 
Le discord de la chaîne:

  / discord  
 
Si après avoir visionné la vidéo vous voulez en savoir plus voilà quelques articles, livres et vidéos que je recommanderais:


Vidéos: 

3Blue1Brown But what is a Neural Network?:    • But what is a neural network? | Chapt...  
Neural Networks training macheads101:    • Neural Networks (Part 2) - Training  
MIT Neural Nets:    • 12a: Neural Nets  
CallTech Lecture10 - Neural Networks:    • Lecture 10 - Neural Networks  

Articles:

A Step by Step Backpropagation Example: https://mattmazur.com/2015/03/17/a-st...
Backpropagation concept explained in 5 levels of difficulty:   / backpropagation-concept-explained-in-5-lev...  
A gentle introduction to calculus: http://makeyourownneuralnetwork.blogs...

Livres:

Make Your Own Neural Network: An In-depth Visual Introduction For Beginners Michael Taylor
Calculus Made Easy de S.P Thompson (Les mathématiques à conaître pour la backpropagation)</dcterms:abstract>
        <dc:date>2019-08-17</dc:date>
        <z:libraryCatalog>YouTube</z:libraryCatalog>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://www.youtube.com/watch?v=gPVVsw2OWdM</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:40:28</dcterms:dateSubmitted>
        <z:runningTime>11:09</z:runningTime>
    </bib:Recording>
    <rdf:Description rdf:about="https://fr.wikipedia.org/w/index.php?title=Algorithme_NEAT&amp;oldid=209732901">
        <z:itemType>encyclopediaArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Book><dc:title>Wikipédia</dc:title></bib:Book>
        </dcterms:isPartOf>
        <link:link rdf:resource="#item_22"/>
        <dc:title>Algorithme NEAT</dc:title>
        <dcterms:abstract>L'algorithme NEAT (de l'anglais Neuroevolution of augmenting topologies) est un algorithme génétique utilisé pour la génération de réseaux de neurones artificiels développé par Ken Stanley en 2002 lorsqu'il était à l'Université du Texas à Austin. L'algorithme consiste à modifier à la fois les paramètres de pondération et les structures des réseaux de neurones afin d'essayer de trouver un équilibre entre la performance des solutions obtenues et leur diversité. Il est basé sur trois techniques principales : 1. suivre les modifications réalisées sur chaque gène afin de permettre des croisements entre les différentes topologies, 2. appliquer des mutations (l'évolution des espèces) pour conserver les innovations, et 3. développer les topologies pas-à-pas à partir de structures initiales simples (&quot;complexification&quot;).</dcterms:abstract>
        <dc:date>2023-11-18T04:12:38Z</dc:date>
        <z:language>fr</z:language>
        <z:libraryCatalog>Wikipedia</z:libraryCatalog>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://fr.wikipedia.org/w/index.php?title=Algorithme_NEAT&amp;oldid=209732901</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:40:58</dcterms:dateSubmitted>
        <dc:rights>Creative Commons Attribution-ShareAlike License</dc:rights>
        <dc:description>Page Version ID: 209732901</dc:description>
    </rdf:Description>
    <z:Attachment rdf:about="#item_22">
        <z:itemType>attachment</z:itemType>
        <dc:title>Snapshot</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://fr.wikipedia.org/wiki/Algorithme_NEAT</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:41:04</dcterms:dateSubmitted>
        <z:linkMode>1</z:linkMode>
        <link:type>text/html</link:type>
    </z:Attachment>
    <rdf:Description rdf:about="https://fr.wikipedia.org/w/index.php?title=R%C3%A9seau_de_neurones_artificiels&amp;oldid=207713061">
        <z:itemType>encyclopediaArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Book><dc:title>Wikipédia</dc:title></bib:Book>
        </dcterms:isPartOf>
        <link:link rdf:resource="#item_24"/>
        <dc:title>Réseau de neurones artificiels</dc:title>
        <dcterms:abstract>Un réseau de neurones artificiels,, ou réseau neuronal artificiel, est un système dont la conception est à l'origine schématiquement inspirée du fonctionnement des neurones biologiques, et qui par la suite s'est rapproché des méthodes statistiques.
Les réseaux de neurones sont généralement optimisés par des méthodes d'apprentissage de type probabiliste, en particulier bayésien. Ils sont placés d'une part dans la famille des applications statistiques, qu'ils enrichissent avec un ensemble de paradigmes permettant de créer des classifications rapides (réseaux de Kohonen en particulier), et d'autre part dans la famille des méthodes de l'intelligence artificielle auxquelles ils fournissent un mécanisme perceptif indépendant des idées propres de l'implémenteur, et des informations d'entrée au raisonnement logique formel (voir Apprentissage profond).
En modélisation des circuits biologiques, ils permettent de tester quelques hypothèses fonctionnelles issues de la neurophysiologie, ou encore les conséquences de ces hypothèses pour les comparer au réel.</dcterms:abstract>
        <dc:date>2023-09-09T14:32:37Z</dc:date>
        <z:language>fr</z:language>
        <z:libraryCatalog>Wikipedia</z:libraryCatalog>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://fr.wikipedia.org/w/index.php?title=R%C3%A9seau_de_neurones_artificiels&amp;oldid=207713061</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:41:24</dcterms:dateSubmitted>
        <dc:rights>Creative Commons Attribution-ShareAlike License</dc:rights>
        <dc:description>Page Version ID: 207713061</dc:description>
    </rdf:Description>
    <z:Attachment rdf:about="#item_24">
        <z:itemType>attachment</z:itemType>
        <dc:title>Snapshot</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://fr.wikipedia.org/wiki/R%C3%A9seau_de_neurones_artificiels</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:41:30</dcterms:dateSubmitted>
        <z:linkMode>1</z:linkMode>
        <link:type>text/html</link:type>
    </z:Attachment>
    <bib:Article rdf:about="https://dl.acm.org/doi/10.1145/2907674.2907678">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:1931-8499"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mitchell</foaf:surname>
                        <foaf:givenName>Melanie</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_25"/>
        <dc:title>Melanie Mitchell</dc:title>
        <dcterms:abstract>Genetic algorithms (GAs) are computer programs that mimic the processes of biological evolution in order to solve problems and to model evolutionary systems. In this paper I describe the appeal of using ideas from evolution to solve computational problems, give the elements of simple GAs, survey some application areas of GAs, and give a detailed example of how a GA was used on one particularly interesting problem—automatically discovering good strategies for playing the Prisoner’s Dilemma. The paper concludes with a short introduction to the theory of GAs.</dcterms:abstract>
        <dc:date>2016-03-24</dc:date>
        <z:language>en</z:language>
        <z:libraryCatalog>DOI.org (Crossref)</z:libraryCatalog>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://dl.acm.org/doi/10.1145/2907674.2907678</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:42:55</dcterms:dateSubmitted>
        <bib:pages>4-4</bib:pages>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:1931-8499">
        <prism:volume>8</prism:volume>
        <dc:title>ACM SIGEVOlution</dc:title>
        <dc:identifier>DOI 10.1145/2907674.2907678</dc:identifier>
        <prism:number>2</prism:number>
        <dcterms:alternative>SIGEVOlution</dcterms:alternative>
        <dc:identifier>ISSN 1931-8499</dc:identifier>
    </bib:Journal>
    <z:Attachment rdf:about="#item_25">
        <z:itemType>attachment</z:itemType>
        <dc:title>Mitchell - 2016 - Melanie Mitchell.pdf</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=630a7d2f0506cb5a01b09f07eef8a3b5a3af0387</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:42:53</dcterms:dateSubmitted>
        <z:linkMode>1</z:linkMode>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:978-2-416-01094-1">
        <z:itemType>book</z:itemType>
        <dc:publisher>
           <foaf:Organization><foaf:name>Eyrolles</foaf:name></foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Bersini</foaf:surname>
                        <foaf:givenName>Hugues</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hasselmann</foaf:surname>
                        <foaf:givenName>Ken</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_28"/>
        <dc:title>L'intelligence artificielle en pratique avec Python : Recherche, optimisation, apprentissage Ed. 2</dc:title>
        <dcterms:abstract>Un livre à la fois théorique et pratique
Cet ouvrage à vocation pédagogique a pour but d’aider les débutants et même les praticiens confirmés de l’intelligence artificielle à mieux faire le tri entre certains mécanismes algorithmiques propres à cette discipline et souvent confondus dont les trois fondamentaux : « la recherche », « l’optimisation » et « l’apprentissage ».
Même si le Web regorge de solutions algorithmiques et de codes clés en main mis à disposition des internautes, ces codes constituent rarement la bonne solution pour faire face à un problème. En effet, il faut souvent prendre du recul, et c’est précisément ce que propose cet ouvrage, pour pouvoir trancher entre les différentes offres algorithmiques (les trois fondamentaux) et choisir celle qui sera la plus appropriée au cas de figure que l’on rencontre.
Dix problèmes très classiques de l’univers algorithmique et de l’IA sont abordés dans la 2e édition ce livre. Pour chacun, nous allons détailler l’une ou l’autre méthode issue d’un des trois mécanismes fondamentaux (recherche, optimisation ou apprentissage) :• le jeu du taquin ;• l’algorithme du plus court chemin (celui qu’on trouve dans les GPS) ;• le jeu du sudoku ;• le jeu de Puissance 4 à deux joueurs ;• le jeu du Tetris ; Mis à jour• le jeu du Snake ;• la séparation des spams et des non-spams ;• les règles d’accès au crédit ; Nouveau• les aides au tri de la presse ou des avis de clients ; Nouveau• la reconnaissance sur photo de chiens ou de chats.
À qui s’adresse cet ouvrage ?• Aux étudiants, en informatique ou pas, qui découvrent l’IA dans leur parcours académique• Aux informaticiens, même les plus confirmés, qui se sentent de plus en plus décontenancés devant l’offre pléthorique des recettes d’IA dont ils n’arrivent pas toujours à comprendre « qui fait quoi »
Compléments webLe code source des exemples du livre en Python est disponible sur le site d’accompagnement.</dcterms:abstract>
        <dc:date>2023</dc:date>
        <z:shortTitle>L'intelligence artificielle en pratique avec Python</z:shortTitle>
        <z:libraryCatalog>univ.scholarvox.com</z:libraryCatalog>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://univ.scholarvox.com/catalog/book/docid/88940945?searchterm=algorithme%20g%C3%A9n%C3%A9tique</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:44:00</dcterms:dateSubmitted>
        <dc:identifier>ISBN 978-2-416-01094-1</dc:identifier>
    </bib:Book>
    <z:Attachment rdf:about="#item_28">
        <z:itemType>attachment</z:itemType>
        <dc:title>Snapshot</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://univ.scholarvox.com/catalog/book/docid/88940945?searchterm=algorithme%20g%C3%A9n%C3%A9tique</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:44:05</dcterms:dateSubmitted>
        <z:linkMode>1</z:linkMode>
        <link:type>text/html</link:type>
    </z:Attachment>
    <bib:Book rdf:about="urn:isbn:978-2-10-081926-3">
        <z:itemType>book</z:itemType>
        <dc:publisher>
           <foaf:Organization><foaf:name>Dunod</foaf:name></foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Charniak</foaf:surname>
                        <foaf:givenName>Eugene</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_30"/>
        <dc:title>Introduction au deep learning</dc:title>
        <dcterms:abstract>Cet ouvrage s’adresse aux étudiants en fin de licence et en  master d’informatique ou de maths appliquées, ainsi qu’aux  élèves ingénieurs.L’apprentissage profond (deep learning) a révolutionné l’intelligence  artificielle et s’est très rapidement répandu dans de  nombreux domaines d’activité.Grâce à une approche « orientée projet », ce livre a pour but  d’expliquer les bases du deep learning, depuis les réseaux de  neurones à propagation avant jusqu’aux réseaux non supervisés.Conçu comme un manuel d’apprentissage synthétique, avec  cours et exercices, il s’appuie sur des exemples dans des  domaines comme la vision par ordinateur, la compréhension  des langages naturels ou l’apprentissage par renforcement.Ces exemples sont étudiés avec le logiciel TensorFlow.Les notions théoriques sont illustrées et complétées par une  quarantaine d’exercices, dont la moitié sont corrigés.</dcterms:abstract>
        <dc:date>2021</dc:date>
        <z:libraryCatalog>univ.scholarvox.com</z:libraryCatalog>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://univ.scholarvox.com/catalog/book/docid/88913266?searchterm=r%C3%A9seau%20de%20neurones</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:45:01</dcterms:dateSubmitted>
        <dc:identifier>ISBN 978-2-10-081926-3</dc:identifier>
    </bib:Book>
    <z:Attachment rdf:about="#item_30">
        <z:itemType>attachment</z:itemType>
        <dc:title>Snapshot</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://univ.scholarvox.com/catalog/book/docid/88913266?searchterm=r%C3%A9seau%20de%20neurones</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:45:05</dcterms:dateSubmitted>
        <z:linkMode>1</z:linkMode>
        <link:type>text/html</link:type>
    </z:Attachment>
    <bib:BookSection rdf:about="urn:isbn:978-3-319-93025-1">
        <z:itemType>bookSection</z:itemType>
        <dcterms:isPartOf>
            <bib:Book>
                <dcterms:isPartOf>
                    <bib:Series>
                       <dc:title>Studies in Computational Intelligence</dc:title>
                    </bib:Series>
                </dcterms:isPartOf>
                <dc:identifier>ISBN 978-3-319-93025-1</dc:identifier>
                <dc:title>Evolutionary Algorithms and Neural Networks: Theory and Applications</dc:title>
            </bib:Book>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <vcard:adr>
                    <vcard:Address>
                       <vcard:locality>Cham</vcard:locality>
                    </vcard:Address>
                </vcard:adr>
                <foaf:name>Springer International Publishing</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mirjalili</foaf:surname>
                        <foaf:givenName>Seyedali</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <bib:editors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mirjalili</foaf:surname>
                        <foaf:givenName>Seyedali</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:editors>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Creating Children Solutions</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Half Uniform Crossover</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Main Search Mechanism</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Masked Crossover</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:subject>
            <z:AutomaticTag>
               <rdf:value>Worse Average Results</rdf:value>
            </z:AutomaticTag>
        </dc:subject>
        <dc:title>Genetic Algorithm</dc:title>
        <dcterms:abstract>Genetic Algorithm (GA) is one of the first population-based stochastic algorithm proposed in the history. Similar to other EAs, the main operators of GA are selection, crossover, and mutation. This chapter briefly presents this algorithm and applies it to several case studies to observe its performance.</dcterms:abstract>
        <dc:date>2019</dc:date>
        <z:language>en</z:language>
        <z:libraryCatalog>Springer Link</z:libraryCatalog>
        <dc:identifier>
            <dcterms:URI>
               <rdf:value>https://doi.org/10.1007/978-3-319-93025-1_4</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:45:26</dcterms:dateSubmitted>
        <dc:description>DOI: 10.1007/978-3-319-93025-1_4</dc:description>
        <bib:pages>43-55</bib:pages>
    </bib:BookSection>
    <bib:Article rdf:about="#item_33">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf>
           <bib:Journal></bib:Journal>
        </dcterms:isPartOf>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Gupta</foaf:surname>
                        <foaf:givenName>Neha</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <link:link rdf:resource="#item_32"/>
        <dc:title>Artificial Neural Network</dc:title>
        <dcterms:abstract>The long course of evolution has given the human brain many desirable characteristics not present in Von Neumann or modern parallel computers. These include massive parallelism, distributed representation and computation, learning ability, generalization ability,adaptivity, inherent contextual information processing, fault tolerance, and low energy consumption. It is hoped that devices based on biological neural networks will possess some of these desirable characteristics.On this basic we come out with the concept of artificial neural network. An artificial neural network, often just called a neural network, is a mathematical model inspired by biological neural networks. A neural network consists of an interconnected group of artificial neurons, and it processes information using a connectionist approach to computation. Neural networks have emerged in the past few years as an area of unusual opportunity for research, development and application to a variety of real world problems. Indeed, neural networks exhibit characteristics and capabilities not provided by any other technology. The article discusses the motivations behind the development of ANNs and describes the basic biological neuron. This paper presents a brief tutorial on artificial neural networks, some of the most commonly used ANN models and briefly describes several applications of it.</dcterms:abstract>
        <z:language>en</z:language>
        <z:libraryCatalog>Zotero</z:libraryCatalog>
    </bib:Article>
    <z:Attachment rdf:about="#item_32">
        <z:itemType>attachment</z:itemType>
        <dc:title>Gupta - Artificial Neural Network.pdf</dc:title>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://d1wqtxts1xzle7.cloudfront.net/31377814/Artificial_Neural_Network-libre.pdf?1392407140=&amp;response-content-disposition=inline%3B+filename%3DIISTE_May_30th_Edition_Peer_reviewed_art.pdf&amp;Expires=1703249198&amp;Signature=EP0P6f2MwmJNe-imbwAwo~oXXVXFzCf419-nvTEhZ3u56t5FXrsWhXRrz3ZloIjs7bD1Shnreyi93JX-mpcXOdbmSmyNxbLxrM731wtbXYVoMAVPT-UWDCAme3RV15uIKzcOnxEntzxwPaAOF~Yd4Un~OodERhiCCjFtEshTOdwSA~aHPHJgS0qQOhPLOM4BqEPXl3~Iog8HWg4kAvuqAQdhVzcJeTJ8lFlU1kmzwIBqIHzNtHR~u8aHGyJzFLV1yo7BMZcNiG1ezM87pCWcC5Y5ig6GEDWhEf0RQ36eWwzgrE6fRISFwS6gcL24tETj1jWGkU-VoGD3soazpr4~8Q__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dcterms:dateSubmitted>2023-12-22 11:46:46</dcterms:dateSubmitted>
        <z:linkMode>1</z:linkMode>
        <link:type>application/pdf</link:type>
    </z:Attachment>
    <z:Collection rdf:about="#collection_1">
        <dc:title>Sourcing Veille</dc:title>
        <dcterms:hasPart rdf:resource="https://www.youtube.com/playlist?list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3"/>
        <dcterms:hasPart rdf:resource="https://www.youtube.com/watch?v=ncj_hBfRt-Y&amp;ab_channel=ThibaultNeveu"/>
        <dcterms:hasPart rdf:resource="https://dev.to/n8python/attempting-and-sort-of-succeeding-to-implement-neat-in-javascript-2ea6"/>
        <dcterms:hasPart rdf:resource="https://direct.mit.edu/evco/article/10/2/99-127/1123"/>
        <dcterms:hasPart rdf:resource="https://realpython.com/python-ai-neural-network/"/>
        <dcterms:hasPart rdf:resource="https://www.google.com/search?q=how+to+create+a+neural+network+in+python&amp;rlz=1C1VDKB_frFR1037FR1037&amp;oq=how+to+create+a+neura&amp;gs_lcrp=EgZjaHJvbWUqBwgAEAAYgAQyBwgAEAAYgAQyBggBEEUYOTIHCAIQABiABDIICAMQABgWGB4yCAgEEAAYFhgeMggIBRAAGBYYHjIICAYQABgWGB4yCAgHEAAYFhgeMggICBAAGBYYHjIICAkQABgWGB7SAQkxMjU4N2owajSoAgCwAgA&amp;sourceid=chrome&amp;ie=UTF-8#fpstate=ive&amp;vld=cid:51146c08,vid:MQzG1hfhow4,st:0"/>
        <dcterms:hasPart rdf:resource="https://www.youtube.com/watch?v=L8ypSXwyBds"/>
        <dcterms:hasPart rdf:resource="https://www.youtube.com/watch?v=gPVVsw2OWdM"/>
        <dcterms:hasPart rdf:resource="https://fr.wikipedia.org/w/index.php?title=Algorithme_NEAT&amp;oldid=209732901"/>
        <dcterms:hasPart rdf:resource="https://fr.wikipedia.org/w/index.php?title=R%C3%A9seau_de_neurones_artificiels&amp;oldid=207713061"/>
        <dcterms:hasPart rdf:resource="https://dl.acm.org/doi/10.1145/2907674.2907678"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-2-416-01094-1"/>
        <dcterms:hasPart rdf:resource="urn:isbn:978-2-10-081926-3"/>
        <dcterms:hasPart rdf:resource="#item_33"/>
    </z:Collection>
</rdf:RDF>
